{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./img/NLP_banner.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 文本主题抽取与表示\n",
    "#### \\[稀牛学院 x 网易云课程\\]《AI工程师(自然语言处理)》课程资料 by [@龙心尘](https://blog.csdn.net/longxinchen_ml)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基于tf-idf与text-rank的主题词抽取\n",
    "### 基于 TF-IDF 算法的关键词抽取\n",
    "#### \\[稀牛学院 x 网易云课程\\]《AI工程师(自然语言处理)》课程资料 by [@龙心尘](https://blog.csdn.net/longxinchen_ml)\n",
    "import jieba.analyse\n",
    "\n",
    "* jieba.analyse.extract_tags(sentence, topK=20, withWeight=False, allowPOS=())\n",
    "    * sentence 为待提取的文本\n",
    "    * topK 为返回几个 TF/IDF 权重最大的关键词，默认值为 20\n",
    "    * withWeight 为是否一并返回关键词权重值，默认值为 False\n",
    "    * allowPOS 仅包括指定词性的词，默认值为空，即不筛选\n",
    "\n",
    "### 基于 TextRank 算法的关键词抽取\n",
    "#### \\[稀牛学院 x 网易云课程\\]《AI工程师(自然语言处理)》课程资料 by [@龙心尘](https://blog.csdn.net/longxinchen_ml)\n",
    "* jieba.analyse.textrank(sentence, topK=20, withWeight=False, allowPOS=('ns', 'n', 'vn', 'v')) 直接使用，接口相同，注意默认过滤词性。\n",
    "* jieba.analyse.TextRank() 新建自定义 TextRank 实例\n",
    "\n",
    "算法论文： [TextRank: Bringing Order into Texts](http://web.eecs.umich.edu/~mihalcea/papers/mihalcea.emnlp04.pdf)\n",
    "\n",
    "基本思想:\n",
    "\n",
    "* 将待抽取关键词的文本进行分词\n",
    "* 以固定窗口大小(默认为5，通过span属性调整)，词之间的共现关系，构建图\n",
    "* 计算图中节点的PageRank，注意是无向带权图"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 监督学习与文本打主题标签\n",
    "#### \\[稀牛学院 x 网易云课程\\]《AI工程师(自然语言处理)》课程资料 by [@龙心尘](https://blog.csdn.net/longxinchen_ml)\n",
    "\n",
    "* 如果不要求主题一定是文本中的词呢？\n",
    " * 如果有已经标注好的主题的文本，可以直接用文本分类的技术来识别文本的主题。\n",
    " * 如BOW/CNN/LSTM/BERT等\n",
    "\n",
    " <p align=\"center\">\n",
    " <img src=\"https://github.com/PaddlePaddle/book/blob/develop/05.recommender_system/image/text_cnn.png?raw=true\" width = \"80%\" align=\"center\"/><br/>\n",
    " 卷积神经网络文本分类模型\n",
    " </p>\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 无监督学习与LDA主题模型\n",
    "### 什么是主题模型\n",
    "#### \\[稀牛学院 x 网易云课程\\]《AI工程师(自然语言处理)》课程资料 by [@龙心尘](https://blog.csdn.net/longxinchen_ml)\n",
    "\n",
    "![](img/LDA1.png)\n",
    "\n",
    "### 汪峰歌词的例子\n",
    "#### \\[稀牛学院 x 网易云课程\\]《AI工程师(自然语言处理)》课程资料 by [@龙心尘](https://blog.csdn.net/longxinchen_ml)\n",
    "有一位网友统计了汪峰老师在大陆发行的 9 张专辑中 117 首歌曲的歌词，同一词语在一首歌出现只算一次，形容词、名词和动词的前十名如下表所示（词语后面的数字是出现的次数）：\n",
    "\n",
    "![](img/LDA2.jpg)\n",
    "\n",
    "如果我们随便写一串数字，然后按照数位依次在形容词、名词和动词中取出一个词，连在一起会怎么样呢？\n",
    "例如取圆周率 3.1415926，对应的词语是：坚强，路，飞，自由，雨，埋，迷惘。稍微连接和润色一下：\n",
    "\n",
    "> 坚强的孩子，\n",
    "\n",
    "> 依然前行在路上，\n",
    "\n",
    "> 张开翅膀飞向自由，\n",
    "\n",
    "> 让雨水埋葬他的迷惘。\n",
    "\n",
    "比如某人的生日19820307：自由，桥，再见，迷惘，生命，死，孤独，鸟。润色一下：\n",
    "\n",
    "> 站在通向自由的桥上，\n",
    "\n",
    "> 再见了，迷惘的生命，\n",
    "\n",
    "> 犹如死亡般的孤独，\n",
    "\n",
    "> 将不再桎梏这只小鸟。\n",
    "\n",
    "有没有汪老师的感觉?找个数字试一试。\n",
    "\n",
    "上面根据汪老师的主题风格，我们创作了一首歌。其实我们更关心的是**如何得到这些主题，这就是 topic model 所要解决的问题**。\n",
    "\n",
    "### 基本脉络\n",
    "#### \\[稀牛学院 x 网易云课程\\]《AI工程师(自然语言处理)》课程资料 by [@龙心尘](https://blog.csdn.net/longxinchen_ml)\n",
    "\n",
    "![](img/LDA3.png)\n",
    "\n",
    "### pLSA\n",
    "#### \\[稀牛学院 x 网易云课程\\]《AI工程师(自然语言处理)》课程资料 by [@龙心尘](https://blog.csdn.net/longxinchen_ml)\n",
    "\n",
    "![](img/PLSA1.png)\n",
    "\n",
    "\n",
    "#### 我们看看PLSA的概率图形式：\n",
    "\n",
    "![](img/PLSA3.png)\n",
    "\n",
    "概率图可以很方便地写出所有变量的联合概率公式。\n",
    "* 扩展阅读：[《概率有向图模型》](https://blog.csdn.net/zb1165048017/article/details/60468659)。重点了解“条件局部独立性”，以及以此写出联合概率公式。\n",
    "\n",
    "![](img/probability.jpg)\n",
    "\n",
    "如果直接对这些自变量求偏导数，我们会发现由于自变量包含在对数和中，这个方程的求解很困难。因此对于这样的包含“隐含变量”或者“缺失数据”的概率模型参数估计问题，我们采用EM算法。\n",
    "\n",
    "#### *EM算法求解\n",
    "\n",
    "* 参考文章[](https://kexue.fm/archives/5239)\n",
    "![《从最大似然到EM算法：一致的理解方式》](img/EM1.png)\n",
    "\n",
    "EM算法的步骤本质上是一种交替最优化（二部坐标下降法）：\n",
    "\n",
    "(1)E步骤：求隐含变量Given当前估计的参数条件下的后验概率。\n",
    "\n",
    "(2)M步骤：最大化Complete data对数似然函数的期望，此时我们使用E步骤里计算的隐含变量的后验概率，得到新的参数值。\n",
    "\n",
    "两步迭代进行直到收敛。\n",
    "\n",
    "\n",
    "* E步：\n",
    "![](img/EM3.png)\n",
    "\n",
    "![](img/EM4.png)\n",
    "\n",
    "* M步：\n",
    "![](img/EM2.png)\n",
    "\n",
    "#### *EM算法求解PLSA\n",
    "\n",
    "* 已知量：w,d\n",
    "* 隐变量：z\n",
    "* 参数：P(w|z)，P(z|d)\n",
    "* E:直接写出\n",
    "* M:拉格朗日乘子法求解"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA\n",
    "#### \\[稀牛学院 x 网易云课程\\]《AI工程师(自然语言处理)》课程资料 by [@龙心尘](https://blog.csdn.net/longxinchen_ml)\n",
    "#### 我们看看pLSA与LDA的概率图形式的对比：\n",
    "![](img/LDA5.png)\n",
    "![](img/LDA6.png)\n",
    "\n",
    "参考文章[《共轭分布》](https://www.cnblogs.com/ooon/p/5845917.html),重点了解共轭分布的概念，和明确狄利克雷分布是多项分布的共轭分布。\n",
    "\n",
    "\n",
    "#### *EM算法求解LDA\n",
    "\n",
    "* 已知量：w\n",
    "* 隐变量：z，θ，φ\n",
    "* 参数：a，β\n",
    "* E:直接写不出，需要用变分法近似，或者吉布斯采样\n",
    "* M:坐标下降法求解，可以考虑牛顿法\n",
    "\n",
    "####  *变分法近似\n",
    "\n",
    "![](img/LDA7.png)\n",
    "注意：这里的φ不是隐变量φ，而是变分变量φ（字母不够用了）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基于python的中文关键词抽取与可视化\n",
    "#### \\[稀牛学院 x 网易云课程\\]《AI工程师(自然语言处理)》课程资料 by [@龙心尘](https://blog.csdn.net/longxinchen_ml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基于LDA的新闻主题分析与可视化呈现\n",
    "#### \\[稀牛学院 x 网易云课程\\]《AI工程师(自然语言处理)》课程资料 by [@龙心尘](https://blog.csdn.net/longxinchen_ml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 版权归 © 稀牛学院 所有 保留所有权利\n",
    "![](./img/xiniu_neteasy.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
